{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddb93f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import spatialdata as sd\n",
    "from skimage.measure import regionprops\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from geomloss import SamplesLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from config import DATA_PATH\n",
    "from data import patch_john, patch_harry\n",
    "from models import utils as model_utils\n",
    "from eval import utils as eval_utils\n",
    "\n",
    "# hugginface\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "load_dotenv(dotenv_path=os.path.expanduser('~/hl/.gutinstinct.env'))\n",
    "api_token = os.getenv(\"API_TOKEN\")\n",
    "login(token=api_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec4777ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('compute_r2_pearson', <function compute_r2_pearson at 0x7ca618d7c7c0>), ('compute_r2_spearman', <function compute_r2_spearman at 0x7ca59d0ea020>), ('l1_normalize', <function l1_normalize at 0x7ca59d0eb600>), ('r2_score', <function r2_score at 0x7ca617afe520>), ('zinb_loss', <function zinb_loss at 0x7ca56142fec0>)]\n"
     ]
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "print(getmembers(eval_utils, isfunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e76d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b-evelyntong/miniconda3/envs/gutinstinct/lib/python3.11/site-packages/zarr/creation.py:610: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n"
     ]
    }
   ],
   "source": [
    "zarr_path = osp.join(os.path.expanduser(DATA_PATH), \"UC6_I.zarr/UC6_I.zarr\")\n",
    "sdata = sd.read_zarr(zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f756982",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_patch_train, dataset_patch_val, dataset_patch_test = patch_harry.get_patches(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36cc8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_expression_train = model_utils.get_expression(sdata, dataset_patch_train)\n",
    "dataset_expression_val = model_utils.get_expression(sdata, dataset_patch_val)\n",
    "dataset_expression_test = model_utils.get_expression(sdata, dataset_patch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a2aab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_patch_train, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset_patch_val, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset_patch_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16770c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1536, kernel_size=(32, 32), stride=(32, 32))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): GluMlp(\n",
       "        (fc1): Linear(in_features=1536, out_features=8192, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## instantiate a uni model\n",
    "timm_kwargs = {\n",
    "   'img_size': 224,\n",
    "   'patch_size': 32,\n",
    "   'depth': 24,\n",
    "   'num_heads': 24,\n",
    "   'init_values': 1e-5,\n",
    "   'embed_dim': 1536,\n",
    "   'mlp_ratio': 2.66667*2,\n",
    "   'num_classes': 0,\n",
    "   'no_embed_class': True,\n",
    "   'mlp_layer': timm.layers.SwiGLUPacked,\n",
    "   'act_layer': torch.nn.SiLU,\n",
    "   'reg_tokens': 8,\n",
    "   'dynamic_img_size': True\n",
    "  }\n",
    "model_uni = timm.create_model(\"hf-hub:MahmoodLab/UNI2-h\", pretrained=True, **timm_kwargs)\n",
    "model_uni = model_uni.to('cuda')\n",
    "transform = create_transform(**resolve_data_config(model_uni.pretrained_cfg, model=model_uni))\n",
    "model_uni.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65253897",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings, train_cell_ids = model_utils.extract_features(train_loader, model_uni)\n",
    "val_embeddings, val_cell_ids = model_utils.extract_features(val_loader, model_uni)\n",
    "test_embeddings, test_cell_ids = model_utils.extract_features(test_loader, model_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c6350fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_embeddings, dtype=torch.float32),\n",
    "    torch.tensor(dataset_expression_train, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(val_embeddings, dtype=torch.float32),\n",
    "    torch.tensor(dataset_expression_val, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_embeddings, dtype=torch.float32),\n",
    "    torch.tensor(dataset_expression_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5796da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.5300, Val Loss: 0.0263, Val R2: -1.0504, Val Spearman: 0.0003\n",
      "Epoch 2, Train Loss: 0.0240, Val Loss: 0.0226, Val R2: -0.5553, Val Spearman: 0.0001\n",
      "Epoch 3, Train Loss: 0.0214, Val Loss: 0.0208, Val R2: -0.2469, Val Spearman: 0.0000\n",
      "Epoch 4, Train Loss: 0.0208, Val Loss: 0.0208, Val R2: -0.2496, Val Spearman: 0.0002\n",
      "Epoch 5, Train Loss: 0.0206, Val Loss: 0.0203, Val R2: -0.3063, Val Spearman: 0.0002\n",
      "Epoch 6, Train Loss: 0.0199, Val Loss: 0.0198, Val R2: -0.2984, Val Spearman: -0.0005\n",
      "Epoch 7, Train Loss: 0.0192, Val Loss: 0.0191, Val R2: -0.2497, Val Spearman: -0.0005\n",
      "Epoch 8, Train Loss: 0.0189, Val Loss: 0.0187, Val R2: -0.2463, Val Spearman: -0.0003\n",
      "Epoch 9, Train Loss: 0.0185, Val Loss: 0.0185, Val R2: -0.2379, Val Spearman: -0.0000\n",
      "Epoch 10, Train Loss: 0.0184, Val Loss: 0.0184, Val R2: -0.2447, Val Spearman: -0.0000\n",
      "Epoch 11, Train Loss: 0.0183, Val Loss: 0.0184, Val R2: -0.2527, Val Spearman: -0.0000\n",
      "Epoch 12, Train Loss: 0.0183, Val Loss: 0.0184, Val R2: -0.2555, Val Spearman: -0.0000\n",
      "Epoch 13, Train Loss: 0.0183, Val Loss: 0.0184, Val R2: -0.2573, Val Spearman: -0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m     loss.backward()\n\u001b[32m     42\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     running_train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m train_losses.append(running_train_loss / \u001b[38;5;28mlen\u001b[39m(train_loader))\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# fit fcn model\n",
    "feature_dim = train_embeddings.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(feature_dim, 512),\n",
    "    nn.ReLU(),\n",
    "    # nn.Dropout(0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 460)\n",
    ")\n",
    "model.to('cuda')\n",
    "\n",
    "# some setups\n",
    "criterion = SamplesLoss(\"sinkhorn\", p=2, blur=0.05)\n",
    "lmd = 0        # controls how much we care about the point-wise loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# es logic\n",
    "es = None\n",
    "best_r2 = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to('cuda'), y_batch.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        y_pred_dist = eval_utils.l1_normalize(y_pred)\n",
    "        y_true_dist = eval_utils.l1_normalize(y_batch)\n",
    "\n",
    "        # use both point-wise and distributional loss\n",
    "        mse_loss = F.mse_loss(y_pred, y_batch)\n",
    "        dist_loss = criterion(eval_utils.l1_normalize(y_pred), eval_utils.l1_normalize(y_batch))\n",
    "        loss = lmd * mse_loss + (1 - lmd) * dist_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_train_loss / len(train_loader))\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val, y_val = x_val.to('cuda'), y_val.to('cuda')\n",
    "            y_pred_val = model(x_val)\n",
    "            y_pred_dist_val = eval_utils.l1_normalize(y_pred_val)\n",
    "            y_true_dist_val = eval_utils.l1_normalize(y_val)\n",
    "\n",
    "            # use both point-wise and distributional loss\n",
    "            mse_loss = F.mse_loss(y_pred_val, y_val)\n",
    "            dist_loss = criterion(y_pred_dist_val, y_true_dist_val)\n",
    "            val_loss = lmd * mse_loss + (1 - lmd) * dist_loss\n",
    "\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "            y_true_all.append(y_val.detach().cpu().numpy())\n",
    "            y_pred_all.append(y_pred_val.detach().cpu().numpy())\n",
    "\n",
    "    val_losses.append(running_val_loss / len(val_loader))\n",
    "    val_r2, val_spearman = eval_utils.compute_r2_spearman(y_true_all, y_pred_all)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val R2: {val_r2:.4f}, Val Spearman: {val_spearman:.4f}\")\n",
    "\n",
    "    if es is not None:\n",
    "        if val_r2 < best_r2:\n",
    "            best_r2 = val_r2\n",
    "            counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab3ea725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUQlJREFUeJzt3XlcVWXiBvDncFkvywVRtgTETFBcUnBBUzAMBXM0La1cSzNy6afkpOZeli1ajuM2NgKZlY65jKWplICO4pZoNiLjFIKjkGkKCrK/vz/wHr2y3Qt34/p8P5/7iXvuWd7DgXh8V0kIIUBERERkIaxMXQAiIiIifWK4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4IdKSJElavVJSUhp1nUWLFkGSpAYdm5KSopcyNEZaWhrCw8Ph4uKC5s2b48knn0RycrJWx/7lL3+BJEnYu3dvrft8+umnkCQJ27dv17pMERERiIiI0NgmSRIWLVpU77GJiYmQJAkXL17U+npqe/bsqfUarVq1wvjx43U+Z2Opf0a+/vpro1+byFisTV0AoqYiLS1N4/0777yD5ORkHDhwQGN7+/btG3WdiRMnYuDAgQ06tmvXrkhLS2t0GRoqOzsbAwYMQHBwML788ktUVFQgKSkJJ0+eRL9+/eo9fvTo0Zg1axbi4+Nr/R4kJCSgRYsWGDx4cKPKmpaWhpYtWzbqHPXZs2cPVq9eXWPA2bFjB1xcXAx6faKHFcMNkZZ69uyp8b5FixawsrKqtv1BRUVFUCqVWl+nZcuWDf6j6+LiUm95DGnPnj24desWEhISEBQUBAAYMmSI1se7u7tjyJAh2LlzJ65fvw53d3eNz8+fP4+0tDS88cYbsLGxaVRZTfl9AoAuXbqY9PpElozNUkR6FBERgQ4dOuDgwYPo1asXlEolXn75ZQDAli1bEBUVBW9vbzg4OKBdu3aYPXs2CgsLNc5RU7NUq1at8PTTT2Pv3r3o2rUrHBwcEBQUhPj4eI39amqWGj9+PJycnPDf//4XMTExcHJygq+vL9544w2UlJRoHP+///0Pzz77LJydneHq6opRo0bhxIkTkCQJiYmJ9d6/QqEAAGRmZmr7LatmwoQJKC0txZdfflnts4SEBACQv6eLFy9Gjx490KxZM7i4uKBr167YsGEDtFkPuKZmqaNHj6J3796wt7eHj48P5syZg7KysmrHavMsx48fj9WrV8vXUr/UzVs1NUvl5ORg9OjR8PDwgJ2dHdq1a4fly5ejsrJS3ufixYuQJAnLli3Dxx9/jICAADg5OSEsLAxHjx6t97619fPPP2PIkCFwc3ODvb09Hn/8cXz22Wca+1RWVmLJkiUIDAyEg4MDXF1d0alTJ/zlL3+R9/n9998xadIk+Pr6ws7ODi1atEDv3r3x/fff662sRA9izQ2RnuXm5mL06NF488038d5778HKqurfEBcuXEBMTAymT58OR0dHnD9/Hh988AGOHz9erWmrJmfOnMEbb7yB2bNnw9PTE3//+98xYcIEtGnTBn379q3z2LKyMvzpT3/ChAkT8MYbb+DgwYN45513oFKpsGDBAgBAYWEh+vXrhz/++AMffPAB2rRpg71792LkyJFa3/vw4cMxZ84cxMbGIjg4GG3atNH6WLX+/fvD398f8fHxmDZtmry9oqICn3/+OXr27Ck3u128eBGvvvoq/Pz8AFSFk2nTpuHy5cvyfWnr3LlziIyMRKtWrZCYmAilUok1a9bUGLK0eZbz589HYWEhvv76a40mTW9v7xqv//vvv6NXr14oLS3FO++8g1atWuHbb7/FzJkz8csvv2DNmjUa+69evRpBQUFYsWKFfL2YmBhkZWVBpVLpdO8PyszMRK9eveDh4YGVK1fC3d0dmzZtwvjx4/Hbb7/hzTffBAB8+OGHWLRoEebNm4e+ffuirKwM58+fx82bN+VzjRkzBqdOncK7776Ltm3b4ubNmzh16hSuX7/eqDIS1UkQUYOMGzdOODo6amwLDw8XAMQPP/xQ57GVlZWirKxMpKamCgDizJkz8mcLFy4UD/5q+vv7C3t7e5GdnS1vu3PnjmjWrJl49dVX5W3JyckCgEhOTtYoJwDxj3/8Q+OcMTExIjAwUH6/evVqAUB89913Gvu9+uqrAoBISEio856EEGLXrl3C09NT+Pr6Cl9fX/HLL7/Ue0xN1N+DU6dOydu++eYbAUB8+umnNR5TUVEhysrKxNtvvy3c3d1FZWWl/Fl4eLgIDw/X2B+AWLhwofx+5MiRwsHBQeTl5cnbysvLRVBQkAAgsrKyarxuXc9yypQp1Z6lmr+/vxg3bpz8fvbs2QKAOHbsmMZ+r732mpAkSWRmZgohhMjKyhIARMeOHUV5ebm83/HjxwUA8dVXX9V4PTX1z8jWrVtr3ef5558XdnZ2IicnR2N7dHS0UCqV4ubNm0IIIZ5++mnx+OOP13k9JycnMX369Dr3IdI3NksR6ZmbmxuefPLJatt//fVXvPjii/Dy8oJCoYCNjQ3Cw8MBABkZGfWe9/HHH5drKADA3t4ebdu2RXZ2dr3HSpJUrQNup06dNI5NTU2Fs7NztY68L7zwQr3nB4AjR45g+PDhWLNmDQ4fPgwbGxv069cPWVlZ8j4TJ06Ev79/ved66aWXYGVlpdHslpCQAEdHR42apAMHDqB///5QqVTy93TBggW4fv06rl69qlW51ZKTkxEZGQlPT095m0KhqLHmqrHPsiYHDhxA+/bt0b17d43t48ePhxCiWu3eoEGD5GZAoOp5AtDq50GbskRGRsLX17daWYqKiuSaqO7du+PMmTOYPHky9u3bh4KCgmrn6t69OxITE7FkyRIcPXq0xmY+In1juCHSs5qaHW7fvo0+ffrg2LFjWLJkCVJSUnDixAl5OPOdO3fqPe+DnWsBwM7OTqtjlUol7O3tqx1bXFwsv79+/brGH3a1mrbV5N1330VgYCCGDRsGX19fpKamygEnOzsblZWVOHToEAYNGlTvufz9/REZGYkvv/wSJSUluHbtGr799ls899xzcHZ2BgAcP34cUVFRAKqGhx8+fBgnTpzA3LlzAWj3Pb3f9evX4eXlVW37g9v08Sxru35NPzs+Pj7y5/d78OfBzs6uUddvSFnmzJmDZcuW4ejRo4iOjoa7uzsiIyNx8uRJ+ZgtW7Zg3Lhx+Pvf/46wsDA0a9YMY8eORV5eXqPLSVQb9rkh0rOa5qg5cOAArly5gpSUFPlf+AA0+iaYmru7O44fP15tu7Z/hH755ReNP7gtW7ZEamoqIiIi0K9fP4wfPx7Z2dmYOXOmVuebMGECkpKS8M9//hNXrlxBaWkpJkyYIH++efNm2NjY4Ntvv9UIbjt37tTq/A9yd3ev8V4f3GaoZ+nu7o7c3Nxq269cuQIAaN68eaPOb4iyWFtbIy4uDnFxcbh58ya+//57vPXWWxgwYAAuXboEpVKJ5s2bY8WKFVixYgVycnKwa9cuzJ49G1evXq1zPiOixmDNDZERqAOP+l/Xan/7299MUZwahYeH49atW/juu+80tm/evFmr4zt06IAff/wR586dk7c98sgjSE1NhRACCxcuxOzZs9G6dWutzjd06FC4u7sjPj4eCQkJaNu2LZ544gn5c0mSYG1trdE0c+fOHXz++edanf9B/fr1ww8//IDffvtN3lZRUYEtW7Zo7KfLs9SlNiUyMhLnzp3DqVOnNLZv3LgRkiRpNU+QvkRGRsoh7sGyKJXKGofRu7q64tlnn8WUKVPwxx9/1DjpoZ+fH6ZOnYqnnnqq2n0S6RNrboiMoFevXnBzc0NsbCwWLlwIGxsbfPHFFzhz5oypiyYbN24cPvnkE4wePRpLlixBmzZt8N1332Hfvn0AII/6qs2SJUtw4MABRERE4M9//jO6du2KP/74A7t378b//vc/tGzZEmvXrsXIkSPRrl27estjZ2eHUaNG4a9//SuEEHj//fc1Ph80aBA+/vhjvPjii5g0aRKuX7+OZcuWVQsd2po3bx527dqFJ598EgsWLIBSqcTq1aurDdXX5Vl27NgRAPDBBx8gOjoaCoUCnTp1gq2tbbV9Z8yYgY0bN2LQoEF4++234e/vj927d2PNmjV47bXX0LZt2wbdV21qGzYeHh6OhQsX4ttvv0W/fv2wYMECNGvWDF988QV2796NDz/8UB6NNXjwYHTo0AGhoaFo0aIFsrOzsWLFCvj7++Oxxx5Dfn4++vXrhxdffBFBQUFwdnbGiRMnsHfvXgwbNkyv90OkwcQdmomarNpGSwUHB9e4/5EjR0RYWJhQKpWiRYsWYuLEieLUqVPVRiLVNlpq0KBB1c754Cig2kZLPVjO2q6Tk5Mjhg0bJpycnISzs7MYPny42LNnjwAg/vnPf9b2rZBlZWWJ8ePHCx8fH2FtbS08PDzEc889J9LS0sRvv/0mHn30UeHl5SWP/KnPmTNnBAChUCjElStXqn0eHx8vAgMDhZ2dnWjdurVYunSp2LBhQ7XRTdqMlhJCiMOHD4uePXsKOzs74eXlJf785z+L9evXVzufts+ypKRETJw4UbRo0UJIkqRxngdHSwkhRHZ2tnjxxReFu7u7sLGxEYGBgeKjjz4SFRUVGt9jAOKjjz6q9v2o6Z4epP4Zqe2l/tk5e/asGDx4sFCpVMLW1lZ07ty52oi55cuXi169eonmzZsLW1tb4efnJyZMmCAuXrwohBCiuLhYxMbGik6dOgkXFxfh4OAgAgMDxcKFC0VhYWGd5SRqDEkILWa7IqKH1nvvvYd58+YhJyfH4MsVEBHpA5uliEi2atUqAEBQUBDKyspw4MABrFy5EqNHj2awIaImg+GGiGRKpRKffPIJLl68iJKSEvj5+WHWrFmYN2+eqYtGRKQ1NksRERGRReFQcCIiIrIoDDdERERkURhuiIiIyKI8dB2KKysrceXKFTg7O9c4TT4RERGZHyEEbt26BR8fn3onFX3ows2VK1eqrXRLRERETcOlS5fqnZrioQs36hWFL126BBcXFxOXhoiIiLRRUFAAX19f+e94XR66cKNuinJxcWG4ISIiamK06VLCDsVERERkURhuiIiIyKIw3BAREZFFeej63BARUeNVVFSgrKzM1MUgC2Nra1vvMG9tMNwQEZHWhBDIy8vDzZs3TV0UskBWVlYICAiAra1to87DcENERFpTBxsPDw8olUpOhkp6o55kNzc3F35+fo362WK4ISIirVRUVMjBxt3d3dTFIQvUokULXLlyBeXl5bCxsWnwedihmIiItKLuY6NUKk1cErJU6uaoioqKRp2H4YaIiHTCpigyFH39bDHcEBERkUVhuCEiItJRREQEpk+fbupiUC3YoZiIiCxWfc0c48aNQ2Jios7n3b59e6M6vALA+PHjcfPmTezcubNR56HqGG70pKJS4HphCW4Xl6N1CydTF4eIiADk5ubKX2/ZsgULFixAZmamvM3BwUFj/7KyMq1CS7NmzfRXSNI7NkvpyZWbd9D93R8Qs/KQqYtCRER3eXl5yS+VSgVJkuT3xcXFcHV1xT/+8Q9ERETA3t4emzZtwvXr1/HCCy+gZcuWUCqV6NixI7766iuN8z7YLNWqVSu89957ePnll+Hs7Aw/Pz+sX7++UWVPTU1F9+7dYWdnB29vb8yePRvl5eXy519//TU6duwIBwcHuLu7o3///igsLAQApKSkoHv37nB0dISrqyt69+6N7OzsRpWnKWG40ROVsirpF5dVoriscUPYiIiaCiEEikrLjf4SQujtHmbNmoXXX38dGRkZGDBgAIqLixESEoJvv/0WP//8MyZNmoQxY8bg2LFjdZ5n+fLlCA0NRXp6OiZPnozXXnsN58+fb1CZLl++jJiYGHTr1g1nzpzB2rVrsWHDBixZsgRAVY3UCy+8gJdffhkZGRlISUnBsGHDIIRAeXk5hg4divDwcPz0009IS0vDpEmTHqpRbmyW0hNnO2sorCRUVArk3ymDvY3C1EUiIjK4O2UVaL9gn9Gve+7tAVDa6udP2PTp0zFs2DCNbTNnzpS/njZtGvbu3YutW7eiR48etZ4nJiYGkydPBlAVmD755BOkpKQgKChI5zKtWbMGvr6+WLVqFSRJQlBQEK5cuYJZs2ZhwYIFyM3NRXl5OYYNGwZ/f38AQMeOHQEAf/zxB/Lz8/H000/j0UcfBQC0a9dO5zI0Zay50RNJkuDqUFV7c7OIi8kRETUVoaGhGu8rKirw7rvvolOnTnB3d4eTkxP279+PnJycOs/TqVMn+Wt189fVq1cbVKaMjAyEhYVp1Lb07t0bt2/fxv/+9z907twZkZGR6NixI5577jl8+umnuHHjBoCq/kDjx4/HgAEDMHjwYPzlL3/R6Hv0MGDNjR6plDa4XliKG0Wlpi4KEZFRONgocO7tASa5rr44OjpqvF++fDk++eQTrFixAh07doSjoyOmT5+O0tK6/9/+YEdkSZJQWVnZoDIJIao1I6mb4iRJgkKhQFJSEo4cOYL9+/fjr3/9K+bOnYtjx44hICAACQkJeP3117F3715s2bIF8+bNQ1JSEnr27Nmg8jQ1rLnRI9bcENHDRpIkKG2tjf4yZP+RQ4cOYciQIRg9ejQ6d+6M1q1b48KFCwa7Xk3at2+PI0eOaPQtOnLkCJydnfHII48AqPre9+7dG4sXL0Z6ejpsbW2xY8cOef8uXbpgzpw5OHLkCDp06IAvv/zSqPdgSqy50SNXZdWaGPl3WHNDRNRUtWnTBtu2bcORI0fg5uaGjz/+GHl5eQbpt5Kfn4/Tp09rbGvWrBkmT56MFStWYNq0aZg6dSoyMzOxcOFCxMXFwcrKCseOHcMPP/yAqKgoeHh44NixY/j999/Rrl07ZGVlYf369fjTn/4EHx8fZGZm4j//+Q/Gjh2r9/KbK5PW3KxduxadOnWCi4sLXFxcEBYWhu+++67OY1JTUxESEgJ7e3u0bt0a69atM1Jp68eaGyKipm/+/Pno2rUrBgwYgIiICHh5eWHo0KEGuVZKSgq6dOmi8VqwYAEeeeQR7NmzB8ePH0fnzp0RGxuLCRMmYN68eQAAFxcXHDx4EDExMWjbti3mzZuH5cuXIzo6GkqlEufPn8fw4cPRtm1bTJo0CVOnTsWrr75qkHswR5LQ53g6HX3zzTdQKBRo06YNAOCzzz7DRx99hPT0dAQHB1fbPysrCx06dMArr7yCV199FYcPH8bkyZPx1VdfYfjw4Vpds6CgACqVCvn5+XBxcdHr/Sz+5t9IOHwRr0U8ilkDde8dT0RkzoqLi5GVlYWAgADY29ubujhkger6GdPl77dJm6UGDx6s8f7dd9/F2rVrcfTo0RrDzbp16+Dn54cVK1YAqBradvLkSSxbtkzrcGNIrg5VzVKsuSEiIjIds+lQXFFRgc2bN6OwsBBhYWE17pOWloaoqCiNbQMGDMDJkydRVmb6QOF6dyI/9rkhIiIyHZN3KD579izCwsJQXFwMJycn7NixA+3bt69x37y8PHh6emps8/T0RHl5Oa5duwZvb+9qx5SUlKCkpER+X1BQoN8buI863LDmhoiIyHRMXnMTGBiI06dP4+jRo3jttdcwbtw4nDt3rtb96xr3X5OlS5dCpVLJL19fX/0V/gHq0VIMN0RERKZj8nBja2uLNm3aIDQ0FEuXLkXnzp3xl7/8pcZ9vby8kJeXp7Ht6tWrsLa2hru7e43HzJkzB/n5+fLr0qVLer8HtXujpdgsRUREZComb5Z6kBBCoxnpfmFhYfjmm280tu3fvx+hoaG1LlFvZ2cHOzs7vZezJnKz1B3W3BAREZmKSWtu3nrrLRw6dAgXL17E2bNnMXfuXKSkpGDUqFEAqmpd7p90KDY2FtnZ2YiLi0NGRgbi4+OxYcMGjQXOTEk9WqqotAIl5VwZnIiIyBRMWnPz22+/YcyYMcjNzYVKpUKnTp2wd+9ePPXUUwCqlnS/f6GygIAA7NmzBzNmzMDq1avh4+ODlStXmsUwcABwtreGJAFCAPl3yuDhzJXBiYiIjM2k4WbDhg11fp6YmFhtW3h4OE6dOmWgEjWOlZUElYMNbhaVIb+oDB7OnOSKiIjI2EzeodjSyJ2K2e+GiMhiREREYPr06fL7Vq1ayRPK1kaSJOzcubPR19bXeR4mDDd6puJwcCIiszF48GD079+/xs/S0tIgSVKDWgNOnDiBSZMmNbZ4GhYtWoTHH3+82vbc3FxER0fr9VoPSkxMhKurq0GvYUwMN3rG4eBEROZjwoQJOHDgALKzs6t9Fh8fj8cffxxdu3bV+bwtWrSAUqnURxHr5eXlZbRRv5aC4UbP3OQlGFhzQ0Rkak8//TQ8PDyq9eEsKirCli1bMGHCBFy/fh0vvPACWrZsCaVSiY4dO+Krr76q87wPNktduHABffv2hb29Pdq3b4+kpKRqx8yaNQtt27aFUqlE69atMX/+fHnpoMTERCxevBhnzpyBJEmQJEku84PNUmfPnsWTTz4JBwcHuLu7Y9KkSbh9+7b8+fjx4zF06FAsW7YM3t7ecHd3x5QpUxq1TFFOTg6GDBkCJycnuLi4YMSIEfjtt9/kz8+cOYN+/frB2dkZLi4uCAkJwcmTJwEA2dnZGDx4MNzc3ODo6Ijg4GDs2bOnwWXRhtnNc9PUqWcpvsGaGyJ6GAgBlBUZ/7o2SqCWmenvZ21tjbFjxyIxMRELFiyQZ7PfunUrSktLMWrUKBQVFSEkJASzZs2Ci4sLdu/ejTFjxqB169bo0aNHvdeorKzEsGHD0Lx5cxw9ehQFBQUa/XPUnJ2dkZiYCB8fH5w9exavvPIKnJ2d8eabb2LkyJH4+eefsXfvXnz//fcAAJVKVe0cRUVFGDhwIHr27IkTJ07g6tWrmDhxIqZOnaoR4JKTk+Ht7Y3k5GT897//xciRI/H444/jlVdeqfd+HiSEwNChQ+Ho6IjU1FSUl5dj8uTJGDlyJFJSUgAAo0aNQpcuXbB27VooFAqcPn1ann9uypQpKC0txcGDB+Ho6Ihz587ByclJ53LoguFGz1QOXF+KiB4iZUXAez7Gv+5bVwBbR612ffnll/HRRx8hJSUF/fr1A1DVJDVs2DC4ubnBzc1NY760adOmYe/evdi6datW4eb7779HRkYGLl68iJYtWwIA3nvvvWr9ZObNmyd/3apVK7zxxhvYsmUL3nzzTTg4OMDJyQnW1tbw8vKq9VpffPEF7ty5g40bN8LRser+V61ahcGDB+ODDz6Q1190c3PDqlWroFAoEBQUhEGDBuGHH35oULj5/vvv8dNPPyErK0tewujzzz9HcHAwTpw4gW7duiEnJwd//vOfERQUBAB47LHH5ONzcnIwfPhwdOzYEQDQunVrncugKzZL6RlnKSYiMi9BQUHo1asX4uPjAQC//PILDh06hJdffhkAUFFRgXfffRedOnWCu7s7nJycsH//fo151uqSkZEBPz8/OdgAVTPqP+jrr7/GE088AS8vLzg5OWH+/PlaX+P+a3Xu3FkONgDQu3dvVFZWIjMzU94WHBwMheLeXGve3t64evWqTte6/5q+vr4aazO2b98erq6uyMjIAADExcVh4sSJ6N+/P95//3388ssv8r6vv/46lixZgt69e2PhwoX46aefGlQOXbDmRs/U4SafNTdE9DCwUVbVopjiujqYMGECpk6ditWrVyMhIQH+/v6IjIwEACxfvhyffPIJVqxYgY4dO8LR0RHTp09Haal23QvUCzjf78HFnI8ePYrnn38eixcvxoABA6BSqbB582YsX75cp/sQQtS6UPT92x9ckkiSJFRWVup0rfquef/2RYsW4cUXX8Tu3bvx3XffYeHChdi8eTOeeeYZTJw4EQMGDMDu3buxf/9+LF26FMuXL8e0adMaVB5tsOZGz9RLMNy8wz43RPQQkKSq5iFjv7Tob3O/ESNGQKFQ4Msvv8Rnn32Gl156Sf7DfOjQIQwZMgSjR49G586d0bp1a1y4cEHrc7dv3x45OTm4cuVeyEtLS9PY5/Dhw/D398fcuXMRGhqKxx57rNoILltbW1RU1L10T/v27XH69GkUFhZqnNvKygpt27bVusy6UN/f/QtPnzt3Dvn5+WjXrp28rW3btpgxYwb279+PYcOGISEhQf7M19cXsbGx2L59O9544w18+umnBimrGsONnqmU7HNDRGRunJycMHLkSLz11lu4cuUKxo8fL3/Wpk0bJCUl4ciRI8jIyMCrr76KvLw8rc/dv39/BAYGYuzYsThz5gwOHTqEuXPnauzTpk0b5OTkYPPmzfjll1+wcuVK7NixQ2OfVq1aISsrC6dPn8a1a9dqXER61KhRsLe3x7hx4/Dzzz8jOTkZ06ZNw5gxY+T+Ng1VUVGB06dPa7zOnTuH/v37o1OnThg1ahROnTqF48ePY+zYsQgPD0doaCju3LmDqVOnIiUlBdnZ2Th8+DBOnDghB5/p06dj3759yMrKwqlTp3DgwAGNUGQIDDd6pp7nhs1SRETmZcKECbhx4wb69+8PPz8/efv8+fPRtWtXDBgwABEREfDy8sLQoUO1Pq+VlRV27NiBkpISdO/eHRMnTsS7776rsc+QIUMwY8YMTJ06FY8//jiOHDmC+fPna+wzfPhwDBw4EP369UOLFi1qHI6uVCqxb98+/PHHH+jWrRueffZZREZGYtWqVbp9M2pw+/ZtdOnSReMVExMjD0V3c3ND37590b9/f7Ru3RpbtmwBACgUCly/fh1jx45F27ZtMWLECERHR2Px4sUAqkLTlClT0K5dOwwcOBCBgYFYs2ZNo8tbF0nU1FhowQoKCqBSqZCfnw8XFxe9n/+PwlJ0fadqfoML70bDRsH8SESWobi4GFlZWQgICIC9PdfOI/2r62dMl7/f/MurZ+qh4ABQwBFTRERERsdwo2cKKwku9lWD0G6waYqIiMjoGG4MQD1LcT5HTBERERkdw40BuHLEFBERkckw3BgAl2AgIkv2kI1DISPS188Ww40BqJuluAQDEVkS9ay3RUUmWCiTHgrqWaHvXzqiIbj8ggHcm+uGfW6IyHIoFAq4urrKaxQplcpalwIg0lVlZSV+//13KJVKWFs3Lp4w3BgAF88kIkulXrG6oYswEtXFysoKfn5+jQ7NDDcGwD43RGSpJEmCt7c3PDw8UFbG/8eRftna2sLKqvE9ZhhuDMCNfW6IyMIpFIpG94sgMhR2KDaAe0PB2eeGiIjI2BhuDIDz3BAREZkOw40BqBzuNkux5oaIiMjoGG4MQF1zU1BcjopKTnZFRERkTAw3BsCVwYmIiEyH4cYAbBRWcLKrGojGEVNERETGxXBjIPfmumG/GyIiImNiuDEQzlJMRERkGgw3BqKeyC+fw8GJiIiMiuHGQFR3a25usFmKiIjIqBhuDMSV60sRERGZBMONgaj73OSzzw0REZFRMdwYiCtnKSYiIjIJhhsDUXG0FBERkUkw3BgI+9wQERGZBsONgbiqh4Kz5oaIiMioGG4MRJ7Ej31uiIiIjIrhxkDuHy1VyZXBiYiIjIbhxkDUa0tVCuBWcbmJS0NERPTwYLgxEDtrBZS2CgDAzTtsmiIiIjIWhhsD4ogpIiIi42O4MSDV3RFTnOuGiIjIeBhuDOhezQ2bpYiIiIzFpOFm6dKl6NatG5ydneHh4YGhQ4ciMzOzzmNSUlIgSVK11/nz541Uau1xfSkiIiLjM2m4SU1NxZQpU3D06FEkJSWhvLwcUVFRKCwsrPfYzMxM5Obmyq/HHnvMCCXWzb25bhhuiIiIjMXalBffu3evxvuEhAR4eHjgxx9/RN++fes81sPDA66urgYsXeOp5MUzGW6IiIiMxaz63OTn5wMAmjVrVu++Xbp0gbe3NyIjI5GcnFzrfiUlJSgoKNB4GYubvHgm+9wQEREZi9mEGyEE4uLi8MQTT6BDhw617uft7Y3169dj27Zt2L59OwIDAxEZGYmDBw/WuP/SpUuhUqnkl6+vr6FuoRo2SxERERmfJIQwi7UBpkyZgt27d+Nf//oXWrZsqdOxgwcPhiRJ2LVrV7XPSkpKUFJSIr8vKCiAr68v8vPz4eLi0uhy12Xvz3mI3fQjuvq5Yvvk3ga9FhERkSUrKCiASqXS6u+3WdTcTJs2Dbt27UJycrLOwQYAevbsiQsXLtT4mZ2dHVxcXDRexiLX3HC0FBERkdGYtEOxEALTpk3Djh07kJKSgoCAgAadJz09Hd7e3nouXePJQ8HZLEVERGQ0Jg03U6ZMwZdffol//vOfcHZ2Rl5eHgBApVLBwcEBADBnzhxcvnwZGzduBACsWLECrVq1QnBwMEpLS7Fp0yZs27YN27ZtM9l91MbV4d4MxUIISJJk4hIRERFZPpOGm7Vr1wIAIiIiNLYnJCRg/PjxAIDc3Fzk5OTIn5WWlmLmzJm4fPkyHBwcEBwcjN27dyMmJsZYxdaauuamolLgdkk5nO1tTFwiIiIiy2c2HYqNRZcOSfoQOO87lJRX4tCb/eDbTGnw6xEREVmiJteh2JJxCQYiIiLjYrgxMDclZykmIiIyJoYbA1PdXRn8BlcGJyIiMgqGGwPjXDdERETGxXBjYOrh4PmsuSEiIjIKhhsD4/pSRERExsVwY2AqNksREREZFcONgcmzFLPmhoiIyCgYbgzs3jw37HNDRERkDAw3BubqwD43RERExsRwY2CuynuLZxIREZHhMdwY2L3RUqV4yJbxIiIiMgmGGwNTh5uyCoGi0goTl4aIiMjyMdwYmIONAraKqm8zm6aIiIgMj+HGwCRJujfXDWcpJiIiMjiGGyNQj5jK54gpIiIig2O4MQIunklERGQ8DDdGoOIsxUREREbDcGME92pu2OeGiIjI0BhujMBNyT43RERExsJwYwTqWYpvcLQUERGRwTHcGIGK60sREREZDcONEXC0FBERkfEw3BiB693RUuxzQ0REZHgMN0bA0VJERETGw3BjBOxzQ0REZDwMN0agrrkpKa9EcRlXBiciIjIkhhsjcLKzhrWVBIC1N0RERIbGcGMEkiSx3w0REZGRMNwYibrfzY1C1twQEREZEsONkahnKc5nzQ0REZFBMdwYiStHTBERERkFw42RqDhLMRERkVEw3BiJepZi1twQEREZFsONkahHS7HPDRERkWEx3BiJPBScNTdEREQGxXBjJFyCgYiIyDgYbozE7e5QcHYoJiIiMiyGGyO51yzFPjdERESGxHBjJBwtRUREZBwMN0ainufmTlkFVwYnIiIyIIYbI3G2s8bdhcFRwH43REREBsNwYyRWVtK9EVMMN0RERAbDcGNE6sUz2e+GiIjIcBhujOjeXDccMUVERGQoJg03S5cuRbdu3eDs7AwPDw8MHToUmZmZ9R6XmpqKkJAQ2Nvbo3Xr1li3bp0RStt4rlw8k4iIyOBMGm5SU1MxZcoUHD16FElJSSgvL0dUVBQKCwtrPSYrKwsxMTHo06cP0tPT8dZbb+H111/Htm3bjFjyhlFP5JfPZikiIiKDsTblxffu3avxPiEhAR4eHvjxxx/Rt2/fGo9Zt24d/Pz8sGLFCgBAu3btcPLkSSxbtgzDhw83dJEbRd0sdYPNUkRERAZjVn1u8vPzAQDNmjWrdZ+0tDRERUVpbBswYABOnjyJsrLqNSIlJSUoKCjQeJkKm6WIiIgMz2zCjRACcXFxeOKJJ9ChQ4da98vLy4Onp6fGNk9PT5SXl+PatWvV9l+6dClUKpX88vX11XvZteV6t+aGzVJERESGYzbhZurUqfjpp5/w1Vdf1buvJEka74UQNW4HgDlz5iA/P19+Xbp0ST8FbgB5KPgdNksREREZikn73KhNmzYNu3btwsGDB9GyZcs69/Xy8kJeXp7GtqtXr8La2hru7u7V9rezs4OdnZ1ey9tQKnnxTNbcEBERGYpJa26EEJg6dSq2b9+OAwcOICAgoN5jwsLCkJSUpLFt//79CA0NhY2NjaGKqheuDgw3REREhmbScDNlyhRs2rQJX375JZydnZGXl4e8vDzcuXNH3mfOnDkYO3as/D42NhbZ2dmIi4tDRkYG4uPjsWHDBsycOdMUt6ATdbNUPjsUExERGYxJw83atWuRn5+PiIgIeHt7y68tW7bI++Tm5iInJ0d+HxAQgD179iAlJQWPP/443nnnHaxcudLsh4ED92pubpeUo6yi0sSlISIiskwm7XOj7ghcl8TExGrbwsPDcerUKQOUyLBcHGwgSYAQVbU3zZ3Moy8QERGRJTGb0VIPA4WVBBd7ri9FRERkSAw3RubKEVNEREQGxXBjZBwxRUREZFgMN0amkifyY7ghIiIyBIYbI7tXc8M+N0RERIbAcGNk6j43nOuGiIjIMBhujIx9boiIiAyL4cbI2OeGiIjIsHQON3fu3EFRUZH8Pjs7GytWrMD+/fv1WjBL5aZknxsiIiJD0jncDBkyBBs3bgQA3Lx5Ez169MDy5csxZMgQrF27Vu8FtDSc54aIiMiwdA43p06dQp8+fQAAX3/9NTw9PZGdnY2NGzdi5cqVei+gpVE5qJulWHNDRERkCDqHm6KiIjg7OwMA9u/fj2HDhsHKygo9e/ZEdna23gtoaVhzQ0REZFg6h5s2bdpg586duHTpEvbt24eoqCgAwNWrV+Hi4qL3Aloa9WipW8XlKOfK4ERERHqnc7hZsGABZs6ciVatWqFHjx4ICwsDUFWL06VLF70X0NKo7oYbACgoLjdhSYiIiCyTta4HPPvss3jiiSeQm5uLzp07y9sjIyPxzDPP6LVwlshaYQVnO2vcKinHzaJSNHO0NXWRiIiILIrO4QYAvLy84OXlBQAoKCjAgQMHEBgYiKCgIL0WzlKplDZV4YZz3RAREemdzs1SI0aMwKpVqwBUzXkTGhqKESNGoFOnTti2bZveC2iJ5CUY2KmYiIhI73QONwcPHpSHgu/YsQNCCNy8eRMrV67EkiVL9F5AS+Sm5HBwIiIiQ9E53OTn56NZs2YAgL1792L48OFQKpUYNGgQLly4oPcCWiJ1p+Ibhay5ISIi0jedw42vry/S0tJQWFiIvXv3ykPBb9y4AXt7e70X0BLJc92wzw0REZHe6dyhePr06Rg1ahScnJzg7++PiIgIAFXNVR07dtR3+SyS691ZivO5vhQREZHe6RxuJk+ejO7du+PSpUt46qmnYGVVVfnTunVr9rnREmtuiIiIDKdBQ8FDQ0MRGhoKIQSEEJAkCYMGDdJ32SyWus8Nl2AgIiLSP5373ADAxo0b0bFjRzg4OMDBwQGdOnXC559/ru+yWSxXebQUww0REZG+6Vxz8/HHH2P+/PmYOnUqevfuDSEEDh8+jNjYWFy7dg0zZswwRDktyr15btjnhoiISN90Djd//etfsXbtWowdO1beNmTIEAQHB2PRokUMN1pQL57JmhsiIiL907lZKjc3F7169aq2vVevXsjNzdVLoSydulkq/04ZKiuFiUtDRERkWXQON23atME//vGPatu3bNmCxx57TC+FsnTqDsVCAAXFrL0hIiLSJ52bpRYvXoyRI0fi4MGD6N27NyRJwr/+9S/88MMPNYYeqs7W2gqOtgoUllbgZlGZXJNDREREjadzzc3w4cNx7NgxNG/eHDt37sT27dvRvHlzHD9+HM8884whymiROGKKiIjIMBo0z01ISAg2bdqkse23337D22+/jQULFuilYJZO5WCDyzfv4CZHTBEREelVg+a5qUleXh4WL16sr9NZPHk4OGtuiIiI9Epv4YZ0Iy/BwFmKiYiI9IrhxkRUdxfPZLghIiLSL4YbE7m3eCb73BAREemT1h2K4+Li6vz8999/b3RhHiZu8hIMrLkhIiLSJ63DTXp6er379O3bt1GFeZi43m2WusHRUkRERHqldbhJTk42ZDkeOiol15ciIiIyBPa5MRH14plsliIiItIvhhsT4QzFREREhsFwYyL35rkp5crgREREesRwYyLqlcErBXC7tNzEpSEiIrIcDDcmYm+jgL1N1bef/W6IiIj0R+tw8+GHH+LOnTvy+4MHD6KkpER+f+vWLUyePFm/pbNwrpylmIiISO+0Djdz5szBrVu35PdPP/00Ll++LL8vKirC3/72N/2WzsJxlmIiIiL90zrcCCHqfN8QBw8exODBg+Hj4wNJkrBz5846909JSYEkSdVe58+fb3RZTEEdbm6w5oaIiEhvtJ7EzxAKCwvRuXNnvPTSSxg+fLjWx2VmZsLFxUV+36JFC0MUz+DUzVL5nKWYiIhIb0wabqKjoxEdHa3zcR4eHnB1ddV/gYzs3nBw1twQERHpi07h5u9//zucnJwAAOXl5UhMTETz5s0BQKM/jqF16dIFxcXFaN++PebNm4d+/frVum9JSYlGx+eCggJjFFErXIKBiIhI/7QON35+fvj000/l915eXvj888+r7WNI3t7eWL9+PUJCQlBSUoLPP/8ckZGRSElJqXXRzqVLl2Lx4sUGLVdDcbQUERGR/mkdbi5evGjAYmgnMDAQgYGB8vuwsDBcunQJy5YtqzXczJkzB3FxcfL7goIC+Pr6Grys2lA3S+VztBQREZHeNPlJ/Hr27IkLFy7U+rmdnR1cXFw0XuZCvXgma26IiIj0R+twc+zYMXz33Xca2zZu3IiAgAB4eHhg0qRJGn1bjCU9PR3e3t5Gv64+sM8NERGR/mndLLVo0SJERETIo5vOnj2LCRMmYPz48WjXrh0++ugj+Pj4YNGiRVpf/Pbt2/jvf/8rv8/KysLp06fRrFkz+Pn5Yc6cObh8+TI2btwIAFixYgVatWqF4OBglJaWYtOmTdi2bRu2bdum9TXNiZuSfW6IiIj0Tetwc/r0abzzzjvy+82bN6NHjx5yJ2NfX18sXLhQp3Bz8uRJjZFO6r4x48aNQ2JiInJzc5GTkyN/XlpaipkzZ+Ly5ctwcHBAcHAwdu/ejZiYGK2vaU7uXxlcCAFJkkxcIiIioqZP63Bz48YNeHp6yu9TU1MxcOBA+X23bt1w6dIlnS4eERFR50zHiYmJGu/ffPNNvPnmmzpdw5ypR0uVVwoUllbAyc6k0w4RERFZBK373Hh6eiIrKwtAVQ3KqVOnEBYWJn9+69Yt2NjY6L+EFszexgq21lWP4CZnKSYiItILrcPNwIEDMXv2bBw6dAhz5syBUqlEnz595M9/+uknPProowYppKWSJIkjpoiIiPRM63aQJUuWYNiwYQgPD4eTkxM+++wz2Nrayp/Hx8cjKirKIIW0ZK5KG1y9VYJ8jpgiIiLSC63DTYsWLXDo0CHk5+fDyckJCoVC4/OtW7fKSzOQ9jhLMRERkX7p3INVpVLVuL1Zs2aNLszD6N5cN+xzQ0REpA9ah5uXX35Zq/3i4+MbXJiHEfvcEBER6ZfW4SYxMRH+/v7o0qVLncO3STdujlXNUuxzQ0REpB9ah5vY2Fhs3rwZv/76K15++WWMHj2aTVF6oLpbc3OjkM1SRERE+qD1UPA1a9YgNzcXs2bNwjfffANfX1+MGDEC+/btY01OI7hyfSkiIiK90mlVcDs7O7zwwgtISkrCuXPnEBwcjMmTJ8Pf3x+3b982VBktmnq0VD773BAREemFTuHmfpIkQZIkCCFQWVmpzzI9VFw5WoqIiEivdAo3JSUl+Oqrr/DUU08hMDAQZ8+exapVq5CTk8M5bhpIxdFSREREeqV1h+LJkydj8+bN8PPzw0svvYTNmzfD3d3dkGV7KNzf54YrgxMRETWe1uFm3bp18PPzQ0BAAFJTU5Gamlrjftu3b9db4R4GrsqqPjel5ZUoLquEg62iniOIiIioLlqHm7Fjx7JWwQAcbRWwtpJQXilw804pHGwdTF0kIiKiJk2nSfxI/yRJgqvSFtdul+BmURm8VQw3REREjdHg0VKkP+p+NzeKOGKKiIiosRhuzIB6fSnOdUNERNR4DDdmgLMUExER6Q/DjRlQ3Z2lmHPdEBERNR7DjRngLMVERET6w3BjBtjnhoiISH8YbsyAXHPDcENERNRoDDdmQHV3lmI2SxERETUew40ZcGPNDRERkd4w3JgBV46WIiIi0huGGzPA0VJERET6w3BjBlR3w01xWSWKyypMXBoiIqKmjeHGDDjbWUNhVbXiej5nKSYiImoUhhszIEkSVA7sVExERKQPDDdmwlUON+x3Q0RE1BgMN2ZCxcUziYiI9ILhxkxwCQYiIiL9YLgxE26cpZiIiEgvGG7MhLpZ6gZrboiIiBqF4cZMcJZiIiIi/WC4MRPqWYrz2SxFRETUKAw3ZsKVi2cSERHpBcONmeAkfkRERPrBcGMmXO+OluLyC0RERI3DcGMmOEMxERGRfjDcmAl1n5vC0gqUlleauDRERERNF8ONmXCxt4FUtTA4m6aIiIgageHGTFhZ3b8yOJumiIiIGsqk4ebgwYMYPHgwfHx8IEkSdu7cWe8xqampCAkJgb29PVq3bo1169YZvqBGIve7Yc0NERFRg5k03BQWFqJz585YtWqVVvtnZWUhJiYGffr0QXp6Ot566y28/vrr2LZtm4FLahwqJWcpJiIiaixrU148Ojoa0dHRWu+/bt06+Pn5YcWKFQCAdu3a4eTJk1i2bBmGDx9uoFIaD0dMERERNV6T6nOTlpaGqKgojW0DBgzAyZMnUVbW9Gs77i3B0PTvhYiIyFRMWnOjq7y8PHh6emps8/T0RHl5Oa5duwZvb+9qx5SUlKCkpER+X1BQYPByNpQrZykmIiJqtCZVcwMAknq89F1CiBq3qy1duhQqlUp++fr6GryMDSX3ueHimURERA3WpMKNl5cX8vLyNLZdvXoV1tbWcHd3r/GYOXPmID8/X35dunTJGEVtENbcEBERNV6TapYKCwvDN998o7Ft//79CA0NhY2NTY3H2NnZwc7OzhjFazQ3R/a5ISIiaiyT1tzcvn0bp0+fxunTpwFUDfU+ffo0cnJyAFTVuowdO1bePzY2FtnZ2YiLi0NGRgbi4+OxYcMGzJw50xTF1ztXh6pmqRscLUVERNRgJq25OXnyJPr16ye/j4uLAwCMGzcOiYmJyM3NlYMOAAQEBGDPnj2YMWMGVq9eDR8fH6xcudIihoEDgErJZikiIqLGMmm4iYiIkDsE1yQxMbHatvDwcJw6dcqApTIddZ+bfIYbIiKiBmtSHYotnevd0VK3SspRVsGVwYmIiBqC4caMuNjfq0grYKdiIiKiBmG4MSPWCis43w04XDyTiIioYRhuzIwrOxUTERE1CsONmVEPB8/nLMVEREQNwnBjZlhzQ0RE1DgMN2ZGPWLqBsMNERFRgzDcmJl7c92wWYqIiKghGG7MjNwsxdFSREREDcJwY2ZUXBmciIioURhuzIy6zw1rboiIiBqG4cbMsM8NERFR4zDcmBn2uSEiImochhszw3luiIiIGofhxsyo+9wUFJeholKYuDRERERND8ONmVGPlhKCK4MTERE1BMONmbFRWMHJjiuDExERNRTDjRm6N9cNR0wRERHpiuHGDHHEFBERUcMx3JghdbjJ54gpIiIinTHcmCFXh7uzFLNZioiISGcMN2ZIxWYpIiKiBmO4MUOuXDyTiIiowRhuzJDb3Yn88llzQ0REpDOGGzOkbpa6wT43REREOmO4MUNsliIiImo4hhsz5MpmKSIiogZjuDFD91YGZ7MUERGRrhhuzJC6WSr/ThkquTI4ERGRThhuzJDL3XBTKYBbJeUmLg0REVHTwnBjhuxtFHCwUQDgEgxERES6YrgxU/cWz2S/GyIiIl0w3Jgp9YgpDgcnIiLSDcONmVJ3KuZEfkRERLphuDFT6mYpznVDRESkG4YbM3VvrhuGGyIiIl0w3JgplQP73BARETUEw42Z4mgpIiKihmG4MVPyLMWsuSEiItIJw42Zuldzw3BDRESkC4YbM3Wvzw2bpYiIiHTBcGOm3Bw5FJyIiKghGG7MlOt9o6WE4MrgRERE2mK4MVPqPjfllQK3uTI4ERGR1hhuzJS9jQJ21lWPh3PdEBERac/k4WbNmjUICAiAvb09QkJCcOjQoVr3TUlJgSRJ1V7nz583YomNh0swEBER6c6k4WbLli2YPn065s6di/T0dPTp0wfR0dHIycmp87jMzEzk5ubKr8cee8xIJTYuV85STEREpDOThpuPP/4YEyZMwMSJE9GuXTusWLECvr6+WLt2bZ3HeXh4wMvLS34pFAojldi4VJylmIiISGcmCzelpaX48ccfERUVpbE9KioKR44cqfPYLl26wNvbG5GRkUhOTjZkMU1KPUsxa26IiIi0Z22qC1+7dg0VFRXw9PTU2O7p6Ym8vLwaj/H29sb69esREhKCkpISfP7554iMjERKSgr69u1b4zElJSUoKSmR3xcUFOjvJgyMfW6IiIh0Z7JwoyZJksZ7IUS1bWqBgYEIDAyU34eFheHSpUtYtmxZreFm6dKlWLx4sf4KbERuSs5STEREpCuTNUs1b94cCoWiWi3N1atXq9Xm1KVnz564cOFCrZ/PmTMH+fn58uvSpUsNLrOxqfvc3GCzFBERkdZMFm5sbW0REhKCpKQkje1JSUno1auX1udJT0+Ht7d3rZ/b2dnBxcVF49VUcLQUERGR7kzaLBUXF4cxY8YgNDQUYWFhWL9+PXJychAbGwugqtbl8uXL2LhxIwBgxYoVaNWqFYKDg1FaWopNmzZh27Zt2LZtmylvw2Du9blhsxQREZG2TBpuRo4cievXr+Ptt99Gbm4uOnTogD179sDf3x8AkJubqzHnTWlpKWbOnInLly/DwcEBwcHB2L17N2JiYkx1CwbF0VJERES6k8RDtipjQUEBVCoV8vPzzb6J6t9X8jFo5b/QwtkOJ+b2N3VxiIiITEaXv98mX36Baud6d7RUPlcGJyIi0hrDjRlTN0uVVlTiTlmFiUtDRETUNDDcmDGlrQI2iqo5f9jvhoiISDsMN2ZMkiS5aYrhhoiISDsMN2bu3ogpDgcnIiLSBsONmXOVVwZnzQ0REZE2GG7MnIqzFBMREemE4cbM3au5YbMUERGRNhhuzJy6z00+a26IiIi0wnBj5uSaG4YbIiIirTDcmDmVeig4m6WIiIi0wnBj5rh4JhERkW4Ybsycm3p9KQ4FJyIi0grDjZlT97m5wUn8iIiItMJwY+ZUbJYiIiLSCcONmVPX3JSUV6KYK4MTERHVi+HGzDnZWUNhxZXBiYiItMVwY+YkSbo3YorDwYmIiOrFcNMEqDiRHxERkdYYbpoAznVDRESkPYabJsBVnuuGzVJERET1YbhpAri+FBERkfYYbpoAV4eqmpsbDDdERET1YrhpAtQ1N2yWIiIiqh/DTRPAZikiIiLtMdw0AVyCgYiISHsMN02AerTUTa4MTkREVC+GmyZAPc9NPlcGJyIiqhfDTRMg97lhzQ0REVG9GG6aAPVQ8KLSCpSUc2VwIiKiujDcNAHO9ta4uzA48ll7Q0REVCeGmybAykriiCkiIiItMdw0EfKIKYYbIiKiOjHcNBH3am44YoqIiKguDDdNBEdMERERaYfhpom4N9cNww0REVFdGG6aiHuzFLNZioiIqC7Wpi6AxagoB66kAzYOd1/Ke/9V2ACS1KjTc7QUERGRdhhu9KX4JrChf82fSYr7ws4DwUfLbZ1v3UK41VUUnsvEmj+OwspKAYXCClaSFRQKKygUClhJEhQKBRRWVrCysoLCygoKhQQrhTWsrSQorBSwVkiwsrKGQiHBWmEFxd3zWCsUsLKSIN0NYRLU/717C3e/EJJU7TPcv899nz/wn7v71Bzyast+UrWr1HBhWd0VkdWu8cCG+uKnJNVz/nqOr2+HGu9VjxqZr+khxZ8baggrhTU8Wz5qsusz3OhLRRng6g+U3bn7KgREZdVnogIovVX1aqAnATxpC6AMwCV9FJiIiMgwfocbsOiiya7PcKMvLt7A9J/uvReiKvCUFd0NO0X3BZ8Ht9X1WdXXouwOCm4VoKK8HICAEKIqPAlR9cL9X9/9DPfeS/L2u+/v33b3awminpus+/P6jtf9H4D1lUf7azd2f11315XO5SEiMmNlVrYmvT7DjaFIEmBtW/VycG386QCoGn0WIiIiw3Mw8fU5WoqIiIgsCsMNERERWRSGGyIiIrIoJg83a9asQUBAAOzt7RESEoJDhw7VuX9qaipCQkJgb2+P1q1bY926dUYqKRERETUFJg03W7ZswfTp0zF37lykp6ejT58+iI6ORk5OTo37Z2VlISYmBn369EF6ejreeustvP7669i2bZuRS05ERETmShJCmGwMao8ePdC1a1esXbtW3tauXTsMHToUS5curbb/rFmzsGvXLmRkZMjbYmNjcebMGaSlpWl1zYKCAqhUKuTn58PFxaXxN0FEREQGp8vfb5PV3JSWluLHH39EVFSUxvaoqCgcOXKkxmPS0tKq7T9gwACcPHkSZWU1L0tQUlKCgoICjRcRERFZLpOFm2vXrqGiogKenp4a2z09PZGXl1fjMXl5eTXuX15ejmvXrtV4zNKlS6FSqeSXr6+vfm6AiIiIzJLJOxQ/uNaQEKLW9Ydq27+m7Wpz5sxBfn6+/Lp0iWsXEBERWTKTzVDcvHlzKBSKarU0V69erVY7o+bl5VXj/tbW1nB3d6/xGDs7O9jZ2emn0ERERGT2TFZzY2tri5CQECQlJWlsT0pKQq9evWo8JiwsrNr++/fvR2hoKGxsbAxWViIiImo6TNosFRcXh7///e+Ij49HRkYGZsyYgZycHMTGxgKoalIaO3asvH9sbCyys7MRFxeHjIwMxMfHY8OGDZg5c6apboGIiIjMjEkXzhw5ciSuX7+Ot99+G7m5uejQoQP27NkDf39/AEBubq7GnDcBAQHYs2cPZsyYgdWrV8PHxwcrV67E8OHDTXULREREZGZMOs+NKXCeGyIioqZHl7/fJq25MQV1luN8N0RERE2H+u+2NnUyD124uXXrFgBwvhsiIqIm6NatW1CpVHXu89A1S1VWVuLKlStwdnaucz6dhigoKICvry8uXbpk8U1eD9O9Ag/X/fJeLdfDdL+8V8sjhMCtW7fg4+MDK6u6x0M9dDU3VlZWaNmypUGv4eLiYtE/YPd7mO4VeLjul/dquR6m++W9Wpb6amzUTD5DMREREZE+MdwQERGRRWG40SM7OzssXLjwoVju4WG6V+Dhul/eq+V6mO6X9/pwe+g6FBMREZFlY80NERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3OhozZo1CAgIgL29PUJCQnDo0KE6909NTUVISAjs7e3RunVrrFu3zkglbbilS5eiW7ducHZ2hoeHB4YOHYrMzMw6j0lJSYEkSdVe58+fN1KpG27RokXVyu3l5VXnMU3xuQJAq1atanxOU6ZMqXH/pvRcDx48iMGDB8PHxweSJGHnzp0anwshsGjRIvj4+MDBwQERERH497//Xe95t23bhvbt28POzg7t27fHjh07DHQHuqnrfsvKyjBr1ix07NgRjo6O8PHxwdixY3HlypU6z5mYmFjj8y4uLjbw3dStvmc7fvz4amXu2bNnvec1x2db373W9HwkScJHH31U6znN9bkaEsONDrZs2YLp06dj7ty5SE9PR58+fRAdHY2cnJwa98/KykJMTAz69OmD9PR0vPXWW3j99dexbds2I5dcN6mpqZgyZQqOHj2KpKQklJeXIyoqCoWFhfUem5mZidzcXPn12GOPGaHEjRccHKxR7rNnz9a6b1N9rgBw4sQJjftMSkoCADz33HN1HtcUnmthYSE6d+6MVatW1fj5hx9+iI8//hirVq3CiRMn4OXlhaeeekpeb64maWlpGDlyJMaMGYMzZ85gzJgxGDFiBI4dO2ao29BaXfdbVFSEU6dOYf78+Th16hS2b9+O//znP/jTn/5U73ldXFw0nnVubi7s7e0NcQtaq+/ZAsDAgQM1yrxnz546z2muz7a+e33w2cTHx0OSJAwfPrzO85rjczUoQVrr3r27iI2N1dgWFBQkZs+eXeP+b775pggKCtLY9uqrr4qePXsarIyGcPXqVQFApKam1rpPcnKyACBu3LhhvILpycKFC0Xnzp213t9SnqsQQvzf//2fePTRR0VlZWWNnzfV5wpA7NixQ35fWVkpvLy8xPvvvy9vKy4uFiqVSqxbt67W84wYMUIMHDhQY9uAAQPE888/r/cyN8aD91uT48ePCwAiOzu71n0SEhKESqXSb+H0rKZ7HTdunBgyZIhO52kKz1ab5zpkyBDx5JNP1rlPU3iu+saaGy2Vlpbixx9/RFRUlMb2qKgoHDlypMZj0tLSqu0/YMAAnDx5EmVlZQYrq77l5+cDAJo1a1bvvl26dIG3tzciIyORnJxs6KLpzYULF+Dj44OAgAA8//zz+PXXX2vd11Kea2lpKTZt2oSXX3653kVkm+pzVcvKykJeXp7Gc7Ozs0N4eHitv79A7c+6rmPMVX5+PiRJgqura5373b59G/7+/mjZsiWefvpppKenG6eAjZSSkgIPDw+0bdsWr7zyCq5evVrn/pbwbH/77Tfs3r0bEyZMqHffpvpcG4rhRkvXrl1DRUUFPD09NbZ7enoiLy+vxmPy8vJq3L+8vBzXrl0zWFn1SQiBuLg4PPHEE+jQoUOt+3l7e2P9+vXYtm0btm/fjsDAQERGRuLgwYNGLG3D9OjRAxs3bsS+ffvw6aefIi8vD7169cL169dr3N8SnisA7Ny5Ezdv3sT48eNr3acpP9f7qX9Hdfn9VR+n6zHmqLi4GLNnz8aLL75Y58KKQUFBSExMxK5du/DVV1/B3t4evXv3xoULF4xYWt1FR0fjiy++wIEDB7B8+XKcOHECTz75JEpKSmo9xhKe7WeffQZnZ2cMGzaszv2a6nNtjIduVfDGevBfuEKIOv/VW9P+NW03V1OnTsVPP/2Ef/3rX3XuFxgYiMDAQPl9WFgYLl26hGXLlqFv376GLmajREdHy1937NgRYWFhePTRR/HZZ58hLi6uxmOa+nMFgA0bNiA6Oho+Pj617tOUn2tNdP39begx5qSsrAzPP/88KisrsWbNmjr37dmzp0ZH3N69e6Nr167461//ipUrVxq6qA02cuRI+esOHTogNDQU/v7+2L17d51/+Jv6s42Pj8eoUaPq7TvTVJ9rY7DmRkvNmzeHQqGoluqvXr1aLf2reXl51bi/tbU13N3dDVZWfZk2bRp27dqF5ORktGzZUufje/bs2ST/ZeDo6IiOHTvWWvam/lwBIDs7G99//z0mTpyo87FN8bmqR7/p8vurPk7XY8xJWVkZRowYgaysLCQlJdVZa1MTKysrdOvWrck9b29vb/j7+9dZ7qb+bA8dOoTMzMwG/Q431eeqC4YbLdna2iIkJEQeXaKWlJSEXr161XhMWFhYtf3379+P0NBQ2NjYGKysjSWEwNSpU7F9+3YcOHAAAQEBDTpPeno6vL299Vw6wyspKUFGRkatZW+qz/V+CQkJ8PDwwKBBg3Q+tik+14CAAHh5eWk8t9LSUqSmptb6+wvU/qzrOsZcqIPNhQsX8P333zcoeAshcPr06Sb3vK9fv45Lly7VWe6m/GyBqprXkJAQdO7cWedjm+pz1YmpejI3RZs3bxY2NjZiw4YN4ty5c2L69OnC0dFRXLx4UQghxOzZs8WYMWPk/X/99VehVCrFjBkzxLlz58SGDRuEjY2N+Prrr011C1p57bXXhEqlEikpKSI3N1d+FRUVyfs8eK+ffPKJ2LFjh/jPf/4jfv75ZzF79mwBQGzbts0Ut6CTN954Q6SkpIhff/1VHD16VDz99NPC2dnZ4p6rWkVFhfDz8xOzZs2q9llTfq63bt0S6enpIj09XQAQH3/8sUhPT5dHB73//vtCpVKJ7du3i7Nnz4oXXnhBeHt7i4KCAvkcY8aM0Rj9ePjwYaFQKMT7778vMjIyxPvvvy+sra3F0aNHjX5/D6rrfsvKysSf/vQn0bJlS3H69GmN3+OSkhL5HA/e76JFi8TevXvFL7/8ItLT08VLL70krK2txbFjx0xxi7K67vXWrVvijTfeEEeOHBFZWVkiOTlZhIWFiUceeaRJPtv6fo6FECI/P18olUqxdu3aGs/RVJ6rITHc6Gj16tXC399f2Nraiq5du2oMjx43bpwIDw/X2D8lJUV06dJF2NrailatWtX6w2hOANT4SkhIkPd58F4/+OAD8eijjwp7e3vh5uYmnnjiCbF7927jF74BRo4cKby9vYWNjY3w8fERw4YNE//+97/lzy3luart27dPABCZmZnVPmvKz1U9bP3B17hx44QQVcPBFy5cKLy8vISdnZ3o27evOHv2rMY5wsPD5f3Vtm7dKgIDA4WNjY0ICgoym2BX1/1mZWXV+nucnJwsn+PB+50+fbrw8/MTtra2okWLFiIqKkocOXLE+Df3gLrutaioSERFRYkWLVoIGxsb4efnJ8aNGydycnI0ztFUnm19P8dCCPG3v/1NODg4iJs3b9Z4jqbyXA1JEuJuT0giIiIiC8A+N0RERGRRGG6IiIjIojDcEBERkUVhuCEiIiKLwnBDREREFoXhhoiIiCwKww0RERFZFIYbIiJULaK4c+dOUxeDiPSA4YaITG78+PGQJKnaa+DAgaYuGhE1QdamLgAREQAMHDgQCQkJGtvs7OxMVBoiaspYc0NEZsHOzg5eXl4aLzc3NwBVTUZr165FdHQ0HBwcEBAQgK1bt2ocf/bsWTz55JNwcHCAu7s7Jk2ahNu3b2vsEx8fj+DgYNjZ2cHb2xtTp07V+PzatWt45plnoFQq8dhjj2HXrl2GvWkiMgiGGyJqEubPn4/hw4fjzJkzGD16NF544QVkZGQAAIqKijBw4EC4ubnhxIkT2Lp1K77//nuN8LJ27VpMmTIFkyZNwtmzZ7Fr1y60adNG4xqLFy/GiBEj8NNPPyEmJgajRo3CH3/8YdT7JCI9MPXKnURE48aNEwqFQjg6Omq83n77bSFE1Ur1sbGxGsf06NFDvPbaa0IIIdavXy/c3NzE7du35c93794trKysRF5enhBCCB8fHzF37txaywBAzJs3T35/+/ZtIUmS+O677/R2n0RkHOxzQ0RmoV+/fli7dq3GtmbNmslfh4WFaXwWFhaG06dPAwAyMjLQuXNnODo6yp/37t0blZWVyMzMhCRJuHLlCiIjI+ssQ6dOneSvHR0d4ezsjKtXrzb0lojIRBhuiMgsODo6Vmsmqo8kSQAAIYT8dU37ODg4aHU+GxubasdWVlbqVCYiMj32uSGiJuHo0aPV3gcFBQEA2rdvj9OnT6OwsFD+/PDhw7CyskLbtm3h7OyMVq1a4YcffjBqmYnINFhzQ0RmoaSkBHl5eRrbrK2t0bx5cwDA1q1bERoaiieeeAJffPEFjh8/jg0bNgAARo0ahYULF2LcuHFYtGgRfv/9d0ybNg1jxoyBp6cnAGDRokWIjY2Fh4cHoqOjcevWLRw+fBjTpk0z7o0SkcEx3BCRWdi7dy+8vb01tgUGBuL8+fMAqkYybd68GZMnT4aXlxe++OILtG/fHgCgVCqxb98+/N///R+6desGpVKJ4cOH4+OPP5bPNW7cOBQXF+OTTz7BzJkz0bx5czz77LPGu0EiMhpJCCFMXQgiorpIkoQdO3Zg6NChpi4KETUB7HNDREREFoXhhoiIiCwK+9wQkdlj6zkR6YI1N0RERGRRGG6IiIjIojDcEBERkUVhuCEiIiKLwnBDREREFoXhhoiIiCwKww0RERFZFIYbIiIisigMN0RERGRR/h9R8RJaJxWy0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf0abf",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- using a distributional loss in addition to the mse loss does not help the model learn\n",
    "- train loss plateaus exactly at val loss, the model is not able to overfit\n",
    "- R2 indicates that the model is worse than predicting the average\n",
    "- l1 + only wasserstein saw model consistently minimizing loss, but val metrics still bad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gutinstinct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
